import requests
from bs4 import BeautifulSoup

# Function to crawl a URL and extract links
def crawl(url):
    try:
        # Send a GET request to the URL
        response = requests.get(url)

        # Check if the request was successful
        if response.status_code == 200:
            # Parse the HTML content using BeautifulSoup
            soup = BeautifulSoup(response.content, "html.parser")

            # Find all the links on the page
            links = soup.find_all("a")

            # Print the links
            for link in links:
                href = link.get("href")
                if href and not href.startswith("#"):  # Exclude anchor links
                    print(href)
        else:
            print(f"Failed to retrieve {url}")

    except Exception as e:
        print(f"An error occurred: {e}")

# Starting URL
start_url = "https://example.com"

# Set the maximum number of pages to crawl (optional)
max_pages = 10

# List to keep track of visited URLs
visited_urls = []

# Queue for URLs to crawl
url_queue = [start_url]

# Crawl until the queue is empty or the maximum number of pages is reached
while url_queue and (max_pages is None or len(visited_urls) < max_pages):
    # Get the next URL from the queue
    current_url = url_queue.pop(0)

    # Check if the URL has already been visited
    if current_url not in visited_urls:
        print(f"Crawling: {current_url}")
        visited_urls.append(current_url)

        # Crawl the current URL and extract links
        crawl(current_url)

        # Find and enqueue new URLs to crawl
        new_links = set()
        response = requests.get(current_url)
        if response.status_code == 200:
            soup = BeautifulSoup(response.content, "html.parser")
            for link in soup.find_all("a"):
                href = link.get("href")
                if href and not href.startswith("#"):  # Exclude anchor links
                    new_links.add(href)

        # Enqueue new URLs that haven't been visited
        for new_link in new_links:
            if new_link not in visited_urls:
                url_queue.append(new_link)
